ask:
  max-tokens: 500
  model: sonnet
  prompts-folder: Prompts
  provider: claude
  save: true
  lookup-folder: Raw
  save-folder: Posts
  system: Be crisp in your response. Only respond to the prompt using valid markdown
    syntax. Do not explain your response.
  temperature: 0.0
intents:
  lookup-folder: Intents
  max-tokens: 1000
  model: sonnet
  provider: claude
  save: true
  save-folder: Embeds
  system: Only respond to the prompt using valid markdown syntax. When responding
    with markdown headings start at level 2. Do not explain your response.
  temperature: 0.3
merge:
  dest-suffix: expanded
  lookup-folder: Posts
  merge-suffix: merged
  placeholder: '[merge here]'
  prompt-prefix: '> Prompt:'
split:
  context-ratio: 0.8
  model: sonnet
model-context:
  gemini-flash: 1000000
  gemini-pro: 2000000
  gemma: 8192
  gpt4mini: 128000
  gpt4o: 128000
  haiku: 200000
  haiku3: 200000
  llama: 128000
  llava: 4096
  mistral: 128000
  mixtral: 32000
  opus: 200000
  qwen: 128000
  sonar: 128000
  sonnet: 200000
  sonnet3: 200000
model-mapping:
  gemini-flash: gemini-1.5-flash
  gemini-pro: gemini-1.5-pro
  gemma: gemma2
  gpt4mini: gpt-4o-mini
  gpt4o: gpt-4o
  haiku: claude-3-haiku-20240307
  haiku3: anthropic.claude-3-haiku-20240307-v1:0
  llama: llama3.1
  llava: llava
  mistral: mistral-nemo
  mixtral: mixtral-8x7b-32768
  opus: claude-3-opus-20240229
  qwen: qwen2
  sonar: llama-3.1-sonar-large-128k-online
  sonnet: claude-3-5-sonnet-20240620
  sonnet3: anthropic.claude-3-sonnet-20240229-v1:0
provider-model-mapping:
  bedrock:
  - sonnet3
  - haiku3
  claude:
  - sonnet
  - opus
  - haiku
  gemini:
  - gemini-pro
  - gemini-flash
  groq:
  - mixtral
  ollama:
  - llama
  - llava
  - mistral
  - gemma
  - qwen
  openai:
  - gpt4o
  - gpt4mini
  perplexity:
  - sonar
refer-intents-to-expand:
  lookup-folder: Intents
  max-tokens: 4000
  model: sonnet
  provider: claude
  save: true
  save-folder: Intents
  system: You will be given a document about exploring a topic, explaining the topic
    in first paragraph. The document will have headings about user intents to explore
    the topic. These intents will have related prompts to expand on the intent using
    an LLM. Your job is to brainstorm the topic, research popular papers, articles,
    books from experts on the topic. Then add more related intents and prompts to
    the document. Depending on the expected response the prompt should ask for a table,
    list, or narrative format. Respond with the expanded document following the same
    structure as the given document. Do not explain your response.
  temperature: 0.3
refer-post-to-update:
  lookup-folder: Posts
  max-tokens: 4000
  model: sonnet
  provider: claude
  save: true
  save-folder: Posts
  system: You will be given a partially written blog post on a topic. Your job as
    an expert blog writer is to expand the post by adding more content. Your response
    will include the existing post content as is and the new content. Perform these
    actions step by step. 1) Study given post content. 2) Research related popular
    papers, articles, books from experts on the topic. 3) Add more related sections
    and content to the post following the existing structure. 4) Cite relevant research
    where applicable as you add new content to the post. 5) Create a section in the
    end of the document for citations with links. 6) Do not explain your response.
  temperature: 0.5
refer-inline-prompts-to-run:
  lookup-folder: Posts
  max-tokens: 4000
  model: sonnet
  provider: claude
  save: true
  save-folder: Posts
  system: You will be given a post with inline prompts in a markdown blockqoute with
    "Prompt:" as the prefix. Your job is to execute the prompt and replace the blockquote
    and prompt by adding new content and sections. If the prompt asks for content
    to be added in another section of the post, then add the content in the correct
    section and remove the prompt. Your response will include the existing post headings
    with placeholder [merge here] replacing existing content and new generated content
    in new sections. Do not explain your response.
  temperature: 0.3
refer-text-to-extract:
  lookup-folder: Raw
  max-tokens: 4000
  model: sonnet
  provider: claude
  save: true
  save-folder: Posts
  system: Respond only using valid markdown syntax. Follow the prompt as instructed
    and do not explain your response.
  temperature: 0.3
test:
  ask: How old is the oldest pyramid?
  image-path: Images/hackathon.jpg
  vision: How many people are in the image?
validate:
  lookup-folder: Intents
  max-tokens: 4000
  model: gpt4o
  provider: openai
  save: true
  save-folder: Embeds
  system: Only respond to the prompt. Do not explain your response.
  temperature: 0.0
  validate-prompt: You are going to read a prompt and a response from an LLM. Research
    the topic online using reputable sources, then validate the response shared with
    you for accuracy and quality. If there are material improvements then create a
    revised response otherwise return the same response.
vision:
  lookup-folder: Images
  max-tokens: 300
  model: sonar
  provider: perplexity
  save: true
  save-folder: Vision
  system: Analyze the image and respond to the prompt using valid markdown syntax.
    Do not explain your response.
  temperature: 0.5
vision-models:
- sonnet
- gpt4o
- gpt4mini
- opus
- haiku
- gemini-pro
- gemini-flash
- llava
